{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import sys\n",
    "\n",
    "# Ensure the project root is on the Python path\n",
    "sys.path.append('E:/ECE208PROJ/HE2L-Net')\n",
    "from configs import cfgs\n",
    "import torch\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\ECE208PROJ\\HE2L-Net\\sampleimages\n",
      "\n",
      "image 1/1 E:\\ECE208PROJ\\HE2L-Net\\sampleimages\\presentimage3.jpg: 192x640 1 \\lim_, 1 \\to, 1 \\frac, 1 +, 3 -s, 2 6s, 1 9, 1 1, 3 vs, 234.6ms\n",
      "Speed: 1.1ms preprocess, 234.6ms inference, 847.8ms postprocess per image at shape (1, 3, 192, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict19\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('E:\\ECE208PROJ\\HE2L-Net\\weights\\yolo_weights.pt')\n",
    "image_root = cfgs.TRAIN_Rec.DATASET.test_img\n",
    "print(image_root)\n",
    "image_name = 'presentimage3'\n",
    "image_path = os.path.join(image_root, image_name + '.jpg')\n",
    "pred_result = model.predict(image_path, show=True, save=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_boxes = []\n",
    "for box in pred_result.boxes.data:\n",
    "    # Extract tensor and convert to numpy array\n",
    "    x1, y1, x2, y2, conf, cls = box.cpu().numpy()\n",
    "    \n",
    "    # Normalize coordinates\n",
    "    x1_normalized = x1 / pred_result.orig_shape[0]\n",
    "    y1_normalized = y1 / pred_result.orig_shape[1]\n",
    "    x2_normalized = x2 / pred_result.orig_shape[0]\n",
    "    y2_normalized = y2 / pred_result.orig_shape[1]\n",
    "    \n",
    "    # Store the normalized box\n",
    "    normalized_box = (x1_normalized, y1_normalized, x2_normalized, y2_normalized, conf,cls)\n",
    "    normalized_boxes.append(normalized_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_5092\\300261247.py:7: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  class_tensor = torch.tensor(classes, dtype=torch.long)  # Class ID tensor\n"
     ]
    }
   ],
   "source": [
    "# Example input: bbox_coordinates and classes should be populated with your data\n",
    "bbox_coordinates = [box[:4] for box in normalized_boxes]  # Extract x1, y1, x2, y2\n",
    "classes = [box[5] for box in normalized_boxes]  # Extract the class index\n",
    "\n",
    "# Convert lists to tensors\n",
    "bbox_tensor = torch.tensor(bbox_coordinates, dtype=torch.float32)  # Bounding box tensor\n",
    "class_tensor = torch.tensor(classes, dtype=torch.long)  # Class ID tensor\n",
    "\n",
    "# Add an additional dimension using unsqueeze (to simulate batch)\n",
    "bbox_tensor = bbox_tensor.unsqueeze(0)  # Shape now [1, N, 4]\n",
    "class_tensor = class_tensor.unsqueeze(0)  # Shape now [1, N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append('E:\\\\ECE208PROJ\\\\HE2L-Net\\\\model')\n",
    "from model.transformer import TransformerModel, pad_or_truncate_output\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "total_tokens = 60\n",
    "num_special_tokens = 0\n",
    "model = TransformerModel(num_tokens=total_tokens + num_special_tokens, num_special_tokens=num_special_tokens, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6)\n",
    "model = model.to(device)\n",
    "if not cfgs.TRAIN_Com.start_new:\n",
    "    checkpoint_path = \"E:\\\\ECE208PROJ\\\\HE2L-Net\\\\weights\\\\transformer_weights.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)  # Load checkpoint\n",
    "    model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted LaTeX: ['\\\\lim_^}^}^^^}}}}{^']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = model(class_tensor,class_tensor, bbox_tensor,gt=None, visualize=False, src_mask=None) \n",
    "# Decoding output to LaTeX\n",
    "latex_output = model.tensor_to_latex(output)\n",
    "print(\"Predicted LaTeX:\", latex_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
